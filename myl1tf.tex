\documentclass{article}
\usepackage{graphicx}
\usepackage{pdfpages}

\begin{document}

\title{Extensions of L1 Trend Filtering: Seasonality}
\author{David Johnston}

\maketitle

\begin{abstract}
This paper extends and further elucidates ideas from Kim, Koh \& Boyd for L1 regularized
trend filtering and acts a documentation to a repository of a python
implementation using the cvxopt library which can be found at https://github.com/dave31415/myl1tf
\end{abstract}

\section{The primary and dual quadratic programming problems}

We will start off at Section 5.2 of KKB where they state the quadratic programming problem for L1TF
and also state the dual problem.

\begin{eqnarray}
\mbox{minimize} & \frac{1}{2} ~ || y - x ||_2^2  + \lambda ||z||_1 \\
\mbox{subject to} & z = D x
\end{eqnarray}
The first is an $l_2$ norm and the second an $l_1$ norm. The Lagrangian, with a dual variable $\nu \in \mathbf{R}^{n-2}$, is
\[
L(x,z,\nu) =  || y - x ||_2^2  + \lambda ||z||_1 + \nu^T (D x -z)
\]
The dual function is
\[
\mbox{inf}_{x,z} ~ L(x,z,\nu) =
    \left\{
    \begin{array}{ll}
    - \frac{1}{2} ~ \nu^T D D^T \nu + y^T D^T \nu &  - \lambda \mathbf{1} < \nu < \lambda \mathbf{1} \\
  -\infty  & \mbox{otherwise.} \\
  \end{array}
  \right.
\]
and so the dual problem is

\begin{eqnarray}
\mbox{maximize} & -\frac{1}{2} ~ \nu^T D D^T \nu + y^T D^T \nu \\
\mbox{subject to} & - \lambda \mathbf{1} < \nu < \lambda \mathbf{1}
\end{eqnarray}

From the solution $\nu^*$ of the dual problem, we can compute the L1TF solution,
\[
x^* = y - D \nu^*
\]

\section{Seasonality}

As suggested by KKB we can adapt this to add a seasonal component.
\begin{eqnarray}
\mbox{minimize} & \frac{1}{2} ~ || y - x -s||_2^2  + \lambda ||z||_1 \\
\mbox{subject to} & z = D x \\
and & \sum_i^P s_i = 0\\
and & s_{i+P} = s_i
\end{eqnarray}

KKB does not go into detail on how to proceed with this and so we will begin here by deriving
the dual problem. We will do this by putting the constraints on $s$ directly into the
equation to be minimized.

To do this, we define $p$ to be the vector of independent variables defining the periodic components.
This vector has dimension $(P-1)$ as the $P$-th, dependent value is $-\sum_{i=1}^{P-1} p_i$ which enforces the constraint that
they sum to zero. This constraint is required if there is to exists a unique solution as otherwise one could add
any constant to $x$ and subtract it from $s$ without changing the model.

We can define $\tilde{p} \in \mathbf{R}^{P}$ as $\tilde{p} = \left( p,-\sum_{i=1}^{P-1} p_i \right) = T p$.
$T$ will be a $P \times (P-1)$ matrix with a $(P-1)$ identity matrix at the top and an extra row consisting of all -1.
The vector $s$ is now just a periodic re-cycling of $\tilde{p}$ which we can represent as s matrix $B$ which is formed by
row-wise stacking some number (ceil(N/P)) of $P \times P$ identity matrices and truncating rows to dimension $N$. So finally
we can write $s = B T p \equiv Q p$. By doing this we can rewrite the optimization problem as

\begin{eqnarray}
\mbox{minimize} & \frac{1}{2} ~ || y - x - Q p||_2^2  + \lambda ||z||_1 \\
\mbox{subject to} & z = D x
\end{eqnarray}
with the $p \in \mathbf{R}^{(P-1)}$ now unconstrained. To improve stabilization and allow more control over $p$, we will add
a $l_2$ regularization constraint and write our problem.
\begin{eqnarray}
\mbox{minimize} & \frac{1}{2} ~ || y - x - Q p||_2^2  + \lambda ||z||_1 + \eta ~ \frac{1}{2} \tilde{p}^T \tilde{p}\\
\mbox{subject to} & z = D x
\end{eqnarray}

We will now proceed as before and derive the dual problem. To do this we first
write down the Lagrangian
\[
L(x,z,p,\nu,\eta,\lambda) =  R  + \lambda ||z||_1 + \nu^T (D x -z) + \eta ~ \frac{1}{2} p^T H ~p
\]
with  $H = T^T T$ and
\begin{eqnarray}
R & \equiv & || y - x - Q p||_2^2 \\
& = & \frac{1}{2} y^T y + \frac{1}{2} x^T x + \frac{1}{2} p^T Q^T Q p \\
&  & - y^T x - y^T Q p + x^T Q p
\end{eqnarray}

We can calculate $\mbox{inf}_{x,z,p} L(x,z,p,\nu,\eta,\lambda)$ by setting gradients w.r.t. $x$ and $p$ to zero. The
gradients of $R$ are

\begin{eqnarray}
\nabla_x R &  =  &  x^T - y^T - p^T Q^T\\
\nabla_p R &  =  &  \left( x^T - y^T - p^T Q^T \right) Q \\
& = & \left(\nabla_x R \right) Q \\
\end{eqnarray}
and the gradients of $L$ are
\begin{eqnarray}
\nabla_x L &  =  &  x^T - y^T - p^T Q^T + \nu^T D\\
\nabla_p L &  =  &  \left( x^T - y^T - p^T Q^T \right) Q + \nu p^T H \\
\end{eqnarray}


Setting $\nabla_x L$ =0 yields the equation.
\[
y - x - Qp = D^T \nu \label{residual}
\] or
\[
x = y - Qp - D^T \nu
\]
Equation \ref{residual} shows that $D^T \nu$ is the residual.

Setting $\nabla_p L$ =0 yields
\[
p = \eta^{-1} H^{-1} Q^T D^T \nu
\]
and we can use this last equation for $p$ to solve for $x$ and we can write these solutions as
\begin{eqnarray}
p^* & = &  \eta^{-1} H^{-1} Q^T D^T \nu \\
& and & \nonumber \\
x^* & = & y - D^T \nu - \eta^{-1} Q H^{-1} Q^T D^T \nu
\end{eqnarray}
and so once we have a solution for $\nu$ we can use these to obtain separate
solutions for $x$ and $p$.

The more subtle minimization w.r.t. $z$ will result in the same constraint in the dual problem as before. The reader
should ensure that they understand how the terms $\lambda ||z||_1 - \nu^T z$ result in the constraint
$- \lambda \mathbf{1} < \nu < \lambda \mathbf{1}$. One can show that outside of this range, the $inf_z$ of this term
is $-\infty$ (at either $z = \pm \infty$) and within is 0 (at $z=0$) and so any supremum for $\nu$
must lie within.

We then construct the dual problem by plugging these solutions into the Lagrangian and we arrive at
\begin{eqnarray}
\mbox{maximize} & -\frac{1}{2} ~ \nu^T A \nu + y^T D^T \nu \\
\mbox{subject to} & - \lambda \mathbf{1} < \nu < \lambda \mathbf{1}
\end{eqnarray}
with
\[
A = D D^T + \eta^{-1} D Q H^{-1} Q^T D^T
\]
We solve this quadratic programming problem as before for $\nu$ and then use the equations above
to calculate $x$ and $p$ from $\nu$. It is apparent that as $\eta \rightarrow \infty$ (seasonality is suppressed),
$p \rightarrow 0$ and we recover the same solution as before for $x$. We cannot use these equations directly with
the other limit $\eta = 0$, though we will address that in a later section. However there is no problem setting
$\eta$ to a neglibly small number and applying these formula.

\section{Seasonality using $l_1$ regularization}
We can also use an $l_1$ regularization term on the seasonality terms $p$ which will result in
sparse solutions for $p$. That is, with a well chosen regularization parameter,
no seasonality will be used when it isn't really required. This might be more useful than the $l_2$
regularization described above though the solution is a little more complicated.

The situation for $l_1$ regularization is similar to the above for the $x$ coordinate and leads to the
same Equation \ref{residual} for the residual. Submitting this solution for $x$ in terms of $\nu$ and $p$
leads to an optimization problem for $\nu$ and $p$ as follows

\begin{eqnarray}
sup_{\nu} ~ inf_p & -\frac{1}{2} ~ \nu^T D D^T \nu + y^T D^T \nu -\nu^T D Q p + \eta ||T p||_1 \\
\mbox{subject to} & - \lambda \mathbf{1} < \nu < \lambda \mathbf{1}
\end{eqnarray}

We can write $||T p||_1 = ||p||_1 + |u^T p| $ where $u$ is the unity vector $u_i=1$. There are no constraints on
$p$ so this term $|u^T p|$ can be any non-negative number for some choice of $p$ and so
$inf_{p} ~  -\nu^T D Q p + \eta ||T p||_1 = inf_{p} ~  -\nu^T D Q p + \eta ||p||_1 $ and
\[
inf_{p} ~  -\nu^T D Q p + \eta ||p||_1 =
    \left\{
    \begin{array}{ll}
    0 &  - \eta \mathbf{1} <  Q^T D^T \nu < \eta \mathbf{1} \\
  -\infty  & \mbox{otherwise.} \\
  \end{array}
  \right.
\]

This implies that the Lagrangian for $\nu$ to be optimized is the same as the non-seasonal
version but with an additional constraint.

\begin{eqnarray}
\mbox{maximize} & - \frac{1}{2} ~ \nu^T D D^T \nu + y^T D^T \nu \\
\mbox{subject to} & - \lambda \mathbf{1} < \nu < \lambda \mathbf{1} \\
& - \eta \mathbf{1} < Q^T D^T \nu < \eta \mathbf{1} \\
\end{eqnarray}

Notice that the $l_2$ solution leads to a modification of the quadratic form whereas the
$l_1$ problem instead leads to an additional constraint. Both of these are standard quadratic
programming problems that can be solved with any convex optimization library (such as cvxopt for python).
A difference however is that the $l_2$ solution included a simple way of calculating $x$ and $p$ once
$\nu$ has been solved. With the $l_1$ solution here, we have to solve a second optimization problem
in order to separate out the separate components.

To do this, note that after $\nu$ has been solved for, the first $\chi^2$ term is now constant
and so we need to optimize the sum of regularization terms by themselves

\begin{eqnarray}
\mbox{minimize} & ||D x||_1 + (\lambda / \eta) ||T_p||_1 \\
\mbox{subject to} & y - x - Qp = D^T \nu \\
\end{eqnarray}

which we can write solely in terms of $p$ as

\begin{eqnarray}
\mbox{minimize over} ~p : & ||D (y - D^T \nu - Q p)||_1 + (\lambda / \eta) ||T_p||_1 \\
\end{eqnarray}

We can combine these into an extended vector space
\[
w = [D (y - D^T \nu), 0]^T
\]
\[
F = [Q p, -(\lambda/\eta) T]
\]
and write this as
\begin{eqnarray}
\mbox{minimize over}~ p : & ||w-F p||_1 \\
\end{eqnarray}

This is now in the form of a well known problem, the Least Absolute Deviation (LAD) problem and can be written as a
a linear program. The cvxopt library contains a program for solving this problem. Thus,
we can solve for $\nu$ by solving the quadratic programming problem and then solve this equation for $p$ and then
use \ref{residual} to solve for $x$.

\section{Modeling outliers for more robust fits}
Finish

\section{Implementation}
The Githib repository https://github.com/dave31415/myl1tf contains an implementation for this
L1TF modeling with seasonality. This is a fork of the repository
https://github.com/elsonidoq/py-l1tf by Pablo Zivic which implements the
simpler version without seasonality. Both versions are in python and
use the python cvxopt library to solve the quadratic programming problems. Our
version contains some test programs. For example, the following command,
\begin{verbatim}
test_myl1tf.test_l1tf_on_mock_with_period(period=6, eta=1.0,alpha=0.5)
\end{verbatim}
creates a mock data-set, fits the model and displays the following plot.
\begin{figure}
\centering
\includegraphics[width=500pt]{example.png}
\end{figure}
(Note \emph{eta} = $\eta$ and \emph{alpha} = $\lambda$ as \emph{lambda} is a reserved word in python).

\end{document}

